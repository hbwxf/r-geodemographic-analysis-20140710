---
title: "Using R for Geodemographic Analysis"
output:
  html_document:
    toc: true
---

##R Basics

R began as a statistics program, and is still used as one my many users. At a simple level you can type in "3 + 4", press return, and R will respond "7". The code you type in in this tutorial is shown like this:

```{r, comment=NA, eval=FALSE}
3 + 4
```

And R's output is shown like this: 

```{r, echo=FALSE, comment=NA}
7
```

R has developed into a GIS as a result of user contributed packages, or libaries, as R refers to them. We will be using several libaries in this practical, and will load them as necessary. 

*If you are using this worksheet outside of the course, you may need to install the R libaries as well as loading them. To do this, run \"install.package(\"package\_name\").*

We won't spend too much time on the basics of using R - if you want to find out more, there are some good tutorials at http://www.social-statistics.org/?p=764 or http://rpubs.com/nickbearman/gettingstartedwithr. 

We are going to use a program called R Studio, which works on top of R and provides a good user interface. I'll talk a little bit about it in the presentation, but the key areas of the window are these:

(Image of R Studio, different bits highlihgted, console, files/plots, environment, R script)

Open up R Studio (click **Start > All Programs > R Studio > R Studio**) and arrange the windows so you can see the instructions along side R Studio. 

##Index Scores

Index scores are an important part of geodemographic classification as they show how the rate of a particular characteristic is for that particular geogrmographic group compared to the national average. 

For example, the table below shows index scores for broadsheet and tabliod newspaper readership. A score of 100 indicates an OAC SuperGroup where newspaper readership is the same as the national average. The City Living SuperGroup have a score of 144 for broadsheet newspapers, which means the readership of broadsheet newspapers for them is 44% higher than the national average. The Blue Collar Communities SuperGroup have an index score of 73.2, which means their readership of broadsheet newspapers is 21.8% lower (100-73.2 = 21.8) than the national average. 

**Table 1: Index Scores for broadsheet and tabliod newspaper readership**


```{r echo=FALSE, comment=NA, results='asis'}
#load library for table
library(xtable)
#create table with names and values
oac_names <- c("Blue Collar Communities","City Living","Countryside","Prospering Suburbs","Constrained by Circumstances","Typical Traits","Multicultural")
broadsheets <- c(73.2, 144, 103.9, 109.1, 78.2, 97.1, 120.2)
tabloids <- c(110.8,82.2,104.9,94.5,108.4,96.4,96.0)
oac <- data.frame(oac_names,broadsheets,tabloids)
#change column headings
colnames(oac) <- c("OAC SuperGroup", "Broadsheet Index Score","Tabloid Index Score")
#print table in HTML
print(xtable(oac), type="html",include.rownames=FALSE)
```




We are going to make a graph of these values. We're using the `ggplot2` library, but there are many different ways of creating a graph. 

In the R Studio window, click + (img) and choose R Script (use Ctrl-Shift-N).

When writing code for R, as with any programming language, it is good to include comments - these are bits of text that R ignores, but we can use them to explain what is happening. In R, these are lines that start with a #. This is useful if we pass our code on to someone else (so they know what the code is doing) and for ourselves, when we come back to a piece of code six months later and can't remember what it was for!

The code below creates a graph of the index scores. We are going to take this code, and alter it to show the Tabloid news paper data. Copy all the code in the section below and paste it into the R script window at the top.

```{r, comment=NA}
#Load libaries
  library(scales)
  library(ggplot2)
#set up data and data frame
  oac_names <- c("Blue Collar Communities","City Living","Countryside","Prospering Suburbs","Constrained by Circumstances","Typical Traits","Multicultural")
  broadsheets <- c(73.2, 144, 103.9, 109.1, 78.2, 97.1, 120.2)
  oac_broadsheets <- data.frame(oac_names,broadsheets)
#convert the percentage values (e.g. 144%) to decimal increase or decrease (e.g. 0.44)
  oac_broadsheets$broadsheets <-  broadsheets / 100 - 1
#select the colours we are going to use
  my_colour <- c("#33A1C9","#FFEC8B","#A2CD5A","#CD7054","#B7B7B7","#9F79EE","#FCC08F")
#plot the graph - this has several bits to it           
#the first three lines setup the data and type of graph
  ggplot(oac_broadsheets, aes(oac_names, broadsheets)) + 
    geom_bar(stat = "identity", fill = my_colour, position="identity") + 
    theme(axis.text.x=element_text(angle=90,hjust=1,vjust=1,size=8)) + 
  #this line add the lables to each bar
    geom_text(aes(label = paste(round(broadsheets * 100,digits = 0), "%"), vjust = ifelse(broadsheets >= 0, -0.5, 1.5)), size=3) +
  #these lines as the axis labels and these fonts
    theme(axis.title.x = element_text(size=8)) + 
    theme(axis.title.y = element_text(size=8)) + 
    scale_y_continuous("Difference from national average for broadsheet",labels = percent_format()) +
    scale_x_discrete("OAC SuperGroups")
```


This code uses the `ggplot` function to create a nice looking graph of the index scores (above). There is quite a lot going on in this code, but don't worry about trying to understand every command at this point. The key aspect is the `oac_broadsheets` data frame - this is where the data for the graph is stored. You can find out more about any R command by typing `?_command_` into the console. For example, `?ggplot`.

To run the code, either click the 'Run' button (top right) which will run all the code, or highlight the bit you want to run, and then press Ctrl-Enter on the keyboard (hold down Control and press Enter). R should create the graph, as shown in this document. If you get red error messages, check you have copied all of the code and not missed any bits out. 

Now instead of broadsheet readership, we will create a graph for tabloid readership. Firstly in the code you copied into the R Script window, replace this line:

```{r, comment=NA}
broadsheets <- c(73.2, 144, 103.9, 109.1, 78.2, 97.1, 120.2)
```

with this

```{r, comment=NA}
tabloids <- c(110.8,82.2,104.9,94.5,108.4,96.4,96.0)
```

As we're doing tabloids now, we need to replace any instance of broadsheets with tabliods. Change:

```{r, comment=NA}
oac_broadsheets <- data.frame(oac_names,broadsheets)
```

to 

```{r, comment=NA}
oac_tabloids <- data.frame(oac_names,tabloids)
```

And do the same for the rest of the code.

You should end up with a graph like this:

```{r echo=FALSE, comment=NA, results='asis'}
library(scales)
library(ggplot2)
library(xtable)

oac_names <- c("Blue Collar Communities","City Living","Countryside","Prospering Suburbs","Constrained by Circumstances","Typical Traits","Multicultural")

tabloids <- c(110.8,82.2,104.9,94.5,108.4,96.4,96.0)
oac_tabloids <- data.frame(oac_names,tabloids)

#convert the percentage values (e.g. 144%) to decimal increase or decrease (e.g. 0.44)
oac_tabloids$tabloids <-  tabloids / 100 - 1
#select the colours we are going to use
my_colour <- c("#33A1C9","#FFEC8B","#A2CD5A","#CD7054","#B7B7B7","#9F79EE","#FCC08F")
ggplot(oac_tabloids, aes(oac_names, tabloids)) + 
  geom_bar(stat = "identity", fill = my_colour, position="identity") + 
  theme(axis.text.x=element_text(angle=90,hjust=1,vjust=1,size=8)) + 
  #this line add the l ables to each bar
  geom_text(aes(label = paste(round(tabloids * 100,digits = 0), "%"), vjust = ifelse(tabloids >= 0, -0.5, 1.5)), size=3) +
  #these lines as the axis labels and these fonts
  theme(axis.title.x = element_text(size=8)) + 
  theme(axis.title.y = element_text(size=8)) + 
  scale_y_continuous("Difference from national average for broadsheet",labels = percent_format()) +
  scale_x_discrete("OAC SuperGroups")
```


This is our new graph!

#need to have different code to run in R studio, so font isn't too small?

##Geodemographic Map of Liverpool

Now that we know the newspaper readership, it would also be useful to know how the different geodemographic classifications are distriubted across Liverpool. We are going to use the 2001 version of the Output Area Classification (OAC) as described in the presentation. However, first of all we need to read in a shapefile for Liverpool. We are going to be using the 2001 Census geography of Output Areas. 

R uses what it calls a working directory, or a folder where it will store the files you are currently working on. In the 'My Documents' folder, create a folder called 'GIS'. We will then tell R to use this folder as its working direcroty. Run the command below. 

```{r eval=FALSE}
# Set working directory
setwd("M:/GIS/")
```

```{r,echo=FALSE,comment=NA,results='hide'}
setwd("/Users/nickbearman/Dropbox/teaching/2014-liverpool/2014-r-google-workshop/practicals/r-geodemographics")
```



All the data we are using is freely avaliable, and while some of it has already been prepard for you, you don't need to be based at a University to access it. For example, the 2001 Output Area data is avaliable from 
https://geoportal.statistics.gov.uk/geoportal/catalog/main/home.page by searching for Output areas (E+W) 2001 Boundaries (Generalised, Clipped). I have already downloaded this data, and just clipped out the Liverpool area for this exercise. 

To read in the data, we need to load another library. Run the lines of code below which will download and read in the data. 

```{r, comment=NA}
#load library
library(maptools)
#download file
download.file("https://raw.githubusercontent.com/nickbearman/r-geodemographic-analysis-20140710/master/liverpool_OA.zip", "liverpool_OA.zip", method = "curl")
#unzip file
unzip("liverpool_OA.zip")
#read in shapefile
liverpool <- readShapeSpatial('liverpool_OA/liverpool', proj4string = CRS("+init=epsg:27700"))
```

This will read in the shapefile to a SpatialPolygonsDataFrame called `liverpool`. We can have a quick look at the data using the `plot` command. Run:

```{r}
plot(liverpool)
```

This just contains the spatial information. We also need to know which Output Area is in which SuperGroup. 
- Go to http://www.ons.gov.uk/ons/guide-method/geography/products/area-classifications/ns-area-classifications/index/datasets/output-areas/output-areas.html 


- Click **Cluster Membership - Output Areas** (on the right hand side)
- Choose **Download**  and click **Next**
- Choose the **North-West** option
- Download the CSV file.
- Extract the files from the zip file and move `J31A0301_2101_GeoPolicy_NW_OA.CSV` to your working folder. 

#update path and expain working folder

Now run this code to read in the CSV file and rename the columns.

```{r}
#read in OAC by OA csv file
OAC <- read.csv("J31A0301_2101_GeoPolicy_NW_OA.csv",header=TRUE,skip=5)
#select certain columns
OAC <- subset(OAC, select = c("OA_CODE","DATA_VALUE","DATA_VALUE.1","DATA_VALUE.2","DATA_VALUE.3","DATA_VALUE.4","DATA_VALUE.5"))
#rename columns
colnames(OAC) <- c("OA_CODE","Supergroup Name","Supergroup Code","Group Name","Group Code","Subgroup Name","Subgroup Code")
```

##Joining Data

The next stage is to join this data onto the data slot of the OA object. This code uses the `match()` function to examine which rows in the `OAC` data frame match with those in the `liverpool@data` dataframe. The matches are done using the OA code columns in both objects. If you print the first few rows of the data slot for both objects, you will see the fields we will be matching.

```{r comment=NA}
#print first six rows for the data frames we will be joining
head(liverpool@data)
head(OAC)
```

Now we join them together, and then do another `head()` command to show the joined data. 

```{r comment=NA}
#Join OAC classification on to LSOA shapefile
liverpool@data = data.frame(liverpool@data, OAC[match(liverpool@data[, "OA01CDOLD"], OAC[,"OA_CODE"]),])
#Show head of liverpool
head(liverpool@data)
```

Now we have the data prepared, we can map it. The code below is commented, so you can see what is going on. If you have time, feel free to have a go at adjusting the colours or the legend options. 

```{r comment=NA}
#Define a set of colours, one for each of the OAC supergroups
my_colour <- c("#33A1C9","#FFEC8B","#A2CD5A","#CD7054","#B7B7B7","#9F79EE","#FCC08F")
oac_names <- c("Blue collar communities","City Living","Countryside","Prospering suburbs","Constrained by circumstances","Typical traits","Multicultural")
#Create a basic OAC choropleth map
plot(liverpool, col=my_colour[liverpool@data$Supergroup.Code], axes=FALSE,border = NA)
#Add the legend (the oac_names object was created earlier)
legend(x=332210, y=385752, legend=oac_names, fill=my_colour, bty="n", cex=.8, ncol=1)
#Add North Arrow
SpatialPolygonsRescale(layout.north.arrow(2), offset= c(332610,385852), scale = 1600, plot.grid=F)
#Add Scale Bar
SpatialPolygonsRescale(layout.scale.bar(), offset= c(333210,381252), scale= 5000, fill= c("white", "black"), plot.grid= F)
#Add text to scale bar 
text(333410,380952,"0km", cex=.8)
text(333410 + 2500,380952,"2.5km", cex=.8)
text(333410 + 5000,380952,"5km", cex=.8)
#Add a title
title("OAC Group Map of Liverpool")
```



##Lunch

##Calc index scores, based on cross tab

I've provided the index scores for you, but where do they come from?
( do we need to include this???)

include index scores for these. 

Creating an Index Score

Based on numbers of papers sold in diff areas (back calculation)
Avg no of papers 1000000 per day tabloid
100000 per day broadsheet.
 - get rough numbers. 
Variation by OAC group
Calc index scores

##Newspapers example 



(include info on source of the data for newspaper readerships)

If we decide to open a corner shop in a particular location then it might be useful to know what newspapers we are likley to sell most of. We know which OAC Group our corner shop falls into, and we know which classifications tend to read which newspapers, so we can combine the two together to work out which newspapers to stock. 

We've already used the index scores for tabloid and broadsheet newspapers, but we also have index scores for individual titles. This data has come from the "Grand Index" of the 2001 OAC which is a list of index scores of over 400 variables for each demographic classification. You can download it from http://areaclassification.org.uk/2010/09/07/oac-grand-index/ and look at all the different variables. I've cut out a subset and you can load this from a CSV file:

```{r comment=NA}
#download file
download.file("https://raw.githubusercontent.com/nickbearman/r-geodemographic-analysis-20140710/master/newspapers_full.csv", "newspapers_full.csv", method = "curl")
#Read in CSV file called newspapers_full.csv
newspapers_full <- read.csv("newspapers_full.csv",header=TRUE)
#print the whole data frame to view it
newspapers_full
```

This gives us the index scores. For example, newspaper readers from the Bule Collar Communities are less likley than average to read the Independent. Our proposed corner shop is at corodinates 341442,388619 which we can plot on to the map using: (if the map isn't visible, then re-run the code to plot the map)

```{r eval=FALSE}
text(341442,388619,"X", cex=1.2)
```

Our shop is in the 'Prospering Suburbs' SuperGroup, and we can see from the table that it's probably worth stocking the Daily Telegraph, the Times and the Daily Mail. 

What about the Finanical Times? What other things might it be worth considering which papers to stock? 


